{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277c3dd3-9597-4731-9051-340815c9517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ba7112-8800-452f-8614-0908a99637a7",
   "metadata": {},
   "source": [
    "### __Deep Learning workflow:__\n",
    "<font size=3>\n",
    "    \n",
    "1. Import and data pre-processing;   \n",
    "2. Neural network modeling;\n",
    "3. Model compilation;\n",
    "4. Train and validation;\n",
    "5. Final training;\n",
    "6. Test evaluation;\n",
    "7. Saving the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e02c34-a721-4728-a8f5-22efd2f5209e",
   "metadata": {},
   "source": [
    "### __1. Import and data pre-processing:__\n",
    "<font size=3>\n",
    "    \n",
    "1.1 Import data;\\\n",
    "1.2 Data visualization;\\\n",
    "1.3 Feature engineering;\\\n",
    "1.4 Data shuffling;\\\n",
    "1.5 Train, validation, and test tensor divition.\n",
    "\n",
    "Our first task will classify _normal_ and _abnormal_ orthopedic diagnoses from biomechanical features. Our data can be downloaded from the [Kaggle datasets](https://www.kaggle.com/datasets/uciml/biomechanical-features-of-orthopedic-patients?resource=download)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc798d16-acd6-4eb6-a9f9-2bfd01d7b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/column_2C_weka.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7981599f-b0ba-4e3a-8355-24a25c173bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many classes do we have?\n",
    "\n",
    "n_normal = len(df[df['class'] == 'Normal'])\n",
    "n_abnormal = len(df[df['class'] == 'Abnormal'])\n",
    "\n",
    "n_normal, n_abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd07cbd-a2dc-4059-b660-084e0076760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data shuffling:\n",
    "i = np.random.permutation(len(df))\n",
    "\n",
    "df = df.iloc[i, :]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dd85fd-edf4-4ea1-94c8-1758c4791edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features data:\n",
    "df.iloc[:, 0:6].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd56b76-d277-4956-bbb3-3d0da1e4f2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:, 0:6].to_numpy()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef5665-4a91-42fb-86bf-4c9f026e086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target data:\n",
    "df.iloc[:, -1:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaebd8d9-2ddc-4f55-a941-e2ab08bfac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_fn(x):\n",
    "    if x == 'Abnormal': return 1.0\n",
    "    else: return 0.0\n",
    "\n",
    "y = df.iloc[:, -1].apply(label_fn).to_numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04089b08-44b2-4320-94ea-2ad69ff58056",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad8e840-a3db-4656-9043-8fb683873430",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y:\", y.shape)\n",
    "\n",
    "# since x array has 2 dimensions, we'll expand y dimensions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d32961-ac98-432c-a44f-cdbf77b56617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5ed9d2-e240-4b7a-a2ce-cac40935becf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into train, validation and test:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c1ea25-87de-45d3-9ddf-0f52089e2d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6ee328-7fad-4607-b0db-af745fb7e10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can delete unnecessary tansors and dataframe:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297d543-bb47-455f-9cc3-0e129221f760",
   "metadata": {},
   "source": [
    "### __2. Neural network modeling:__\n",
    "<font size=3>\n",
    "    \n",
    "2.1 Define initial layer's shape;\\\n",
    "2.2 Define output layer's shape and its [activation function](https://keras.io/api/layers/activations/);\\\n",
    "2.3 Define hidden layers.\n",
    "\n",
    "[Checkout Keras API](https://keras.io/guides/functional_api/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374e4278-f29c-4b98-8a72-27e222c778e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "626664fc-593b-4539-ac60-4903c5734b58",
   "metadata": {},
   "source": [
    "### __3. Model compilation:__\n",
    "<font size=3>\n",
    "\n",
    "3.1 Define [optimizer](https://keras.io/api/optimizers/);\\\n",
    "3.2 Define [loss function](https://keras.io/api/losses/);\\\n",
    "3.3 Define [validation metric](https://keras.io/api/metrics/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386ed652-4f95-4e71-a75e-e501c3197512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "beda4521-0d6c-42fe-995f-dd52c4ae9bc1",
   "metadata": {},
   "source": [
    "### __4. Train and validation__\n",
    "<font size=3>\n",
    "    \n",
    "Here, using the training data, the optimizer updates the values of the model's inner parameters (_i.e._, weights, biases, etc.) over the epochs while minimizing/maximizing the loss function. Meanwhile, the model's performance is measured for each epoch using the validation data. At this workflow stage, we model the neural network architecture to avoid [overfitting and underfitting](https://www.geeksforgeeks.org/underfitting-and-overfitting-in-machine-learning/)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "52cf656f-ad02-4f75-99f7-591e6b5aafe1",
   "metadata": {
    "scrolled": true
   },
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "21e63123-4b42-4d76-b648-5d1480ca92db",
   "metadata": {
    "scrolled": true
   },
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "c5f7eed7-0c54-4e66-945a-828ae4f0ec8e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e8686e6-36cf-414e-8fed-238a7c2024ad",
   "metadata": {},
   "source": [
    "### __5. Final training__\n",
    "<font size=3>\n",
    "\n",
    "Once the modeling is completed, we concatenate train and validation data to fit again the model.\n",
    "\n",
    "__Note:__ use the same number of epochs from the previous step.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eeec45-6651-4c84-b0d9-55cb31fc4990",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e92f8b8-93b5-4fbf-aaae-d073791c63c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca10e11f-b7c6-48e2-8839-7a031f12f7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0e875dc-7d57-42fb-a03b-19948e2de183",
   "metadata": {},
   "source": [
    "### __6. Test evaluation__:\n",
    "\n",
    "    6.1 Make the evaluation using the test data;\n",
    "    6.1 Make some predictions to visualize the results;\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcc147f-9bdd-46ab-bff4-28fef5f02f86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8671e2-fd04-463a-9400-62ce10da85ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd1006c9-50c7-4341-a265-a9221ae1ebca",
   "metadata": {},
   "source": [
    "### __7. Saving the model__:\n",
    "<font size=3>\n",
    "    \n",
    "[Checkout]((https://keras.io/guides/serialization_and_saving/))."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
