{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a4843d-9240-4dfb-9760-2190f79474a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ba7112-8800-452f-8614-0908a99637a7",
   "metadata": {},
   "source": [
    "### __Deep Learning workflow:__\n",
    "<font size=3>\n",
    "    \n",
    "1. Import and data pre-processing;   \n",
    "2. Neural network modeling;\n",
    "3. Model compilation;\n",
    "4. Train and validation;\n",
    "5. Final training;\n",
    "6. Test evaluation;\n",
    "7. Saving the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e02c34-a721-4728-a8f5-22efd2f5209e",
   "metadata": {},
   "source": [
    "### __1. Import and data pre-processing:__\n",
    "<font size=3>\n",
    "    \n",
    "1.1 Import data;\\\n",
    "1.2 Data visualization;\\\n",
    "1.3 Feature engineering;\\\n",
    "1.4 Data shuffling;\\\n",
    "1.5 Train, validation, and test tensor divition.\n",
    "\n",
    "Our next problem is a supervised regression task using the classical [MNIST](https://en.wikipedia.org/wiki/MNIST_database) handwritten digits. The data is available in the [Keras dataset](https://keras.io/api/datasets/mnist/).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055d678e-0494-4cee-9cae-42fbd0ee9cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import MNIST data:\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "\n",
    "print(f\"x-train:{x_train.shape}, y-train:{y_train.shape}\")\n",
    "print(f\"x-test:{x_test.shape}, y-test:{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b48070-c5ea-4bd1-870e-536a4471aabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing handwritten digits:\n",
    "i = 0\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.title(\"Number \"+str(y_train[i]))\n",
    "plt.imshow(x_train[i], cmap='gray')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3425b4a-e3b5-49c1-872e-8af6d0a51b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling train data:\n",
    "\n",
    "# shuffling test data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc522a2-3cbe-4be6-a6ca-2becf8faf4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c00c1b-6ba4-4f5f-bbfe-9e8d86ba1865",
   "metadata": {},
   "source": [
    "#### __One-hot encoding:__\n",
    "<font size=3>\n",
    "    \n",
    "One-hot encoding is a technique for multiclass data numerical encoding, such as the digit's labels $(0,1,2,3,4,5,6,7,8,9)$. It involves representing a label as the maximum probability in a vector with the same size as the number of classes. This means the label is assigned a vector position with a probability of 1, while the coefficients of the other vectors receive a probability of 0.\n",
    "\n",
    "$0:(1,0,0,0,0,0,0,0,0,0);\\; 1: (0,1,0,0,0,0,0,0,0,0);\\; \\cdots;\\; 9: (0,0,0,0,0,0,0,0,0,1)$\n",
    "\n",
    "For digit $\\mathbf 3$, the model can output $(2.4,6.2,1.2,\\mathbf{9.6},0.8,4.7,3.1,1.7,5.3,4.3)$.\n",
    "\n",
    "We can use TensorFlow's [one_hot](https://www.tensorflow.org/api_docs/python/tf/one_hot) function to do the encoding, or we can do it by \"hand\" as following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f01dce-a8ec-498b-b8f5-e6d74e749985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding for label data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e13249-0816-4175-b2b6-4277c04530ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten x data (the number arrays) as dense layers' input vectors: (N, 28, 28) -> (N, 28*28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf60ef-6ee7-46e2-83c3-9d26025ecf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the train data into train and validation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fb7c82-3045-49c1-a22f-b510d8aeffdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1297d543-bb47-455f-9cc3-0e129221f760",
   "metadata": {},
   "source": [
    "### __2. Neural network modeling:__\n",
    "<font size=3>\n",
    "    \n",
    "2.1 Define initial layer's shape;\\\n",
    "2.2 Define output layer's shape and its [activation function](https://keras.io/api/layers/activations/);\\\n",
    "2.3 Define hidden layers.\n",
    "\n",
    "When the model needs a probability distribution output vector, we use the [softmax activation function](https://en.wikipedia.org/wiki/Softmax_function) to range the values in the interval $[0,\\,1]$ and sum  to $1$, given by\n",
    "$$\n",
    "    \\sigma_l(\\vec a_l) = \\frac{e^{a_l^i}}{\\sum_{j=1} e^{a_l^j}} \\, .\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c34025-d680-4050-a110-8c73e5c0ef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting softmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b666ab3b-0fc6-4ab1-8733-5ebac7dc2d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626664fc-593b-4539-ac60-4903c5734b58",
   "metadata": {},
   "source": [
    "### __3. Model compilation:__\n",
    "<font size=3>\n",
    "\n",
    "3.1 Define [optimizer](https://keras.io/api/optimizers/);\\\n",
    "3.2 Define [loss function](https://keras.io/api/losses/);\\\n",
    "3.3 Define [validation metric](https://keras.io/api/metrics/).\n",
    "\n",
    "For loss function optimization, the [Cross-Entropy function](https://en.wikipedia.org/wiki/Cross-entropy) can be used to handle probability distributions. It measures the match between the predicted distribution $q$ and the true distribution $p$, \n",
    "$$\n",
    "    H(p,\\,q) = -\\sum_i p_i\\,\\ln q_i \\, .\n",
    "$$\n",
    "\n",
    "In Keras, we have a [list of probability losses](https://keras.io/api/losses/) where the [categorical cross-entropy loss](https://keras.io/api/losses/probabilistic_losses/#categoricalcrossentropy-class) is best suited to dealing with multiclass one-hot labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a84098-027b-43c5-ab82-b8120cf530ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2905f12-2b1c-44cd-950d-eb266dc314eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "beda4521-0d6c-42fe-995f-dd52c4ae9bc1",
   "metadata": {},
   "source": [
    "### __4. Train and validation__\n",
    "<font size=3>\n",
    "    \n",
    "Here, using the training data, the optimizer updates the values of the model's inner parameters (_i.e._, weights, biases, etc.) over the epochs while minimizing/maximizing the loss function. Meanwhile, the model's performance is measured for each epoch using the validation data. At this workflow stage, we model the neural network architecture to avoid [overfitting and underfitting](https://www.geeksforgeeks.org/underfitting-and-overfitting-in-machine-learning/).\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25725ffd-a813-4352-a978-79ee74fc000b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5b73d2-f67f-419f-b9d0-19a852fd7260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e8686e6-36cf-414e-8fed-238a7c2024ad",
   "metadata": {},
   "source": [
    "### __5. Final training__\n",
    "<font size=3>\n",
    "\n",
    "Once the modeling is completed, we concatenate train and validation data to fit again the model.\n",
    "\n",
    "__Note:__ use the same number of __epochs__ and __batch-size__ from the previous step.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcc8771-f10b-4a4e-b150-f2b7880f4933",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc59ca5-11e8-42b9-accb-a55520bc85b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0e875dc-7d57-42fb-a03b-19948e2de183",
   "metadata": {},
   "source": [
    "### __6. Test evaluation__:\n",
    "\n",
    "    6.1 Make the evaluation using the test data;\n",
    "    6.1 Make some predictions to visualize the results;\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669ee142-33e3-4451-801c-fd5d00129572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d565f6a8-2c91-47b6-9aee-2cfa8fb1717d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd1006c9-50c7-4341-a265-a9221ae1ebca",
   "metadata": {},
   "source": [
    "### __7. Saving the model__:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f887201-cead-40ec-99cc-7057a328a754",
   "metadata": {},
   "source": [
    "model.save_weights(\"weights/mnist.weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216ee526-ca72-467b-86aa-7fa56c604c7d",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "For model __loading__, see [2.2-notebook](2.2-notebook.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
