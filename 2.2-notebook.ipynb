{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277c3dd3-9597-4731-9051-340815c9517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e02c34-a721-4728-a8f5-22efd2f5209e",
   "metadata": {},
   "source": [
    "### __1. Import and data pre-processing:__\n",
    "<font size=3>\n",
    "    \n",
    "1.1 Import data;\\\n",
    "1.2 Data visualization;\\\n",
    "1.3 Feature engineering;\\\n",
    "1.4 Data shuffling;\\\n",
    "1.5 Train, validation, and test tensor divition.\n",
    "\n",
    "Our first task will classify _normal_ and _abnormal_ orthopedic diagnoses from biomechanical features. Our data can be downloaded from the [Kaggle datasets](https://www.kaggle.com/datasets/uciml/biomechanical-features-of-orthopedic-patients?resource=download)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc798d16-acd6-4eb6-a9f9-2bfd01d7b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/column_2C_weka.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7981599f-b0ba-4e3a-8355-24a25c173bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many classes do we have?\n",
    "\n",
    "n_normal = len(df[df['class'] == 'Normal'])\n",
    "n_abnormal = len(df[df['class'] == 'Abnormal'])\n",
    "\n",
    "n_normal, n_abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd07cbd-a2dc-4059-b660-084e0076760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data shuffling:\n",
    "i = np.random.permutation(len(df))\n",
    "\n",
    "df = df.iloc[i, :]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dd85fd-edf4-4ea1-94c8-1758c4791edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features data:\n",
    "df.iloc[:, 0:6].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd56b76-d277-4956-bbb3-3d0da1e4f2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:, 0:6].to_numpy()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef5665-4a91-42fb-86bf-4c9f026e086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target data:\n",
    "df.iloc[:, -1:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaebd8d9-2ddc-4f55-a941-e2ab08bfac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_fn(x):\n",
    "    if x == 'Abnormal': return 1.0\n",
    "    else: return 0.0\n",
    "\n",
    "y = df.iloc[:, -1].apply(label_fn).to_numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04089b08-44b2-4320-94ea-2ad69ff58056",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad8e840-a3db-4656-9043-8fb683873430",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y:\", y.shape)\n",
    "\n",
    "# since x array has 2 dimensions, we'll expand y dimensions:\n",
    "y = np.expand_dims(y, axis=1)\n",
    "\n",
    "print(\"y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d32961-ac98-432c-a44f-cdbf77b56617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the data:\n",
    "print(f\"x before norm: max = {x.max():.2f}, min = {x.min():.2f}\")\n",
    "\n",
    "x /= abs(x).max() # normalization: x = x/max(abs(x))\n",
    "\n",
    "print(f\"x after norm: max = {x.max():.2f}, min = {x.min():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5ed9d2-e240-4b7a-a2ce-cac40935becf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into train, validation and test:\n",
    "N_samples, N_features = x.shape\n",
    "\n",
    "N_train = int(0.70*N_samples) # 80%\n",
    "\n",
    "N_val = int(0.2*N_samples) # 20%\n",
    "\n",
    "N_test = N_samples - (N_train + N_val) # 10%\n",
    "\n",
    "print(f\"N-samples = {N_samples}, N-train = {N_train}, N-val = {N_val}, N-test = {N_test}\")\n",
    "\n",
    "print(N_samples == N_train + N_val + N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c1ea25-87de-45d3-9ddf-0f52089e2d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x[:N_train]\n",
    "y_train = y[:N_train]\n",
    "\n",
    "x_val = x[N_train:N_train+N_val]\n",
    "y_val = y[N_train:N_train+N_val]\n",
    "\n",
    "x_test = x[N_train+N_val:]\n",
    "y_test = y[N_train+N_val:]\n",
    "\n",
    "print(f\"x-train:{x_train.shape}, y-train:{y_train.shape}\")\n",
    "print(f\"x-val:{x_val.shape}, y-val:{y_val.shape}\")\n",
    "print(f\"x-test:{x_test.shape}, y-test:{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6ee328-7fad-4607-b0db-af745fb7e10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can delete unnecessary tansors and dataframe:\n",
    "\n",
    "del df, x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297d543-bb47-455f-9cc3-0e129221f760",
   "metadata": {},
   "source": [
    "### __2. Import model:__\n",
    "<font size=3>\n",
    "    \n",
    "* Import model from _toolbox_;\n",
    "* Load model's weights and bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc8cffe-e8e5-4167-a0c9-c01d1eaf76df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c7353e-c61a-4a45-8576-2bdd97c4e6a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0e875dc-7d57-42fb-a03b-19948e2de183",
   "metadata": {},
   "source": [
    "### __3. Test evaluation__:\n",
    "\n",
    "    6.1 Make the evaluation using the test data;\n",
    "    6.1 Make some predictions to visualize the results;\n",
    "   "
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ec7b3b8-4b42-460e-bbcd-c973600536c0",
   "metadata": {},
   "source": [
    "model.compile(loss='mse', metrics=['acc'])\n",
    "\n",
    "model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b0c8a50-c1c4-4e0c-94a0-d14d6e670a98",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "pred = model.predict(x_test)\n",
    "\n",
    "for p, y in zip(pred, y_test):\n",
    "    \n",
    "    label = 1.0 if p > 0.5 else 0.0\n",
    "\n",
    "    print(f\"pred = {p[0]:.3f}, label = {label}, y-test = {y[0]}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
