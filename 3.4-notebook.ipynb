{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a4843d-9240-4dfb-9760-2190f79474a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ba7112-8800-452f-8614-0908a99637a7",
   "metadata": {},
   "source": [
    "### __Deep Learning workflow:__\n",
    "<font size=3>\n",
    "    \n",
    "1. Import and data pre-processing;   \n",
    "2. Neural network modeling;\n",
    "3. Model compilation;\n",
    "4. Train and validation;\n",
    "5. Final training;\n",
    "6. Test evaluation;\n",
    "7. Saving the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e02c34-a721-4728-a8f5-22efd2f5209e",
   "metadata": {},
   "source": [
    "### __1. Import and data pre-processing:__\n",
    "<font size=3>\n",
    "    \n",
    "1.1 Import data;\\\n",
    "1.2 Data visualization;\\\n",
    "1.3 Feature engineering;\\\n",
    "1.4 Data shuffling;\\\n",
    "1.5 Train, validation, and test tensor divition.\n",
    "\n",
    "Our next problem is a supervised regression task using the classical [MNIST](https://en.wikipedia.org/wiki/MNIST_database) handwritten digits. The data is available in the [Keras dataset](https://keras.io/api/datasets/mnist/).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055d678e-0494-4cee-9cae-42fbd0ee9cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import MNIST data:\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "\n",
    "print(f\"x-train:{x_train.shape}, y-train:{y_train.shape}\")\n",
    "print(f\"x-test:{x_test.shape}, y-test:{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b48070-c5ea-4bd1-870e-536a4471aabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing handwritten digits:\n",
    "i = 0\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.title(\"Number \"+str(y_train[i]))\n",
    "plt.imshow(x_train[i], cmap='gray')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3425b4a-e3b5-49c1-872e-8af6d0a51b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling train data:\n",
    "i = np.random.permutation(x_train.shape[0])\n",
    "\n",
    "x_train = x_train[i]\n",
    "y_train = y_train[i]\n",
    "\n",
    "# shuffling test data:\n",
    "i = np.random.permutation(x_test.shape[0])\n",
    "\n",
    "x_test = x_test[i]\n",
    "y_test = y_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc522a2-3cbe-4be6-a6ca-2becf8faf4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization:\n",
    "print(f\"train: min = {x_train.min()}, max = {x_train.max()}\")\n",
    "print(f\"test: min = {x_test.min()}, max = {x_test.max()}\\n\")\n",
    "\n",
    "Max = x_train.max()\n",
    "\n",
    "x_train = x_train/Max\n",
    "x_test = x_test/Max\n",
    "\n",
    "print(f\"train: min = {x_train.min()}, max = {x_train.max()}\")\n",
    "print(f\"test: min = {x_test.min()}, max = {x_test.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f01dce-a8ec-498b-b8f5-e6d74e749985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding for label data:\n",
    "\n",
    "def one_hot(labels):\n",
    "    N = labels.size\n",
    "    \n",
    "    y_hot = np.zeros((N, 10), dtype=\"float32\")\n",
    "    \n",
    "    for i, y in enumerate(labels):\n",
    "        y_hot[i][y] = 1\n",
    "\n",
    "    return y_hot\n",
    "\n",
    "print(y_train[:4], \"\\n\")\n",
    "\n",
    "y_train = one_hot(y_train)\n",
    "y_test = one_hot(y_test)\n",
    "\n",
    "print(y_train[:4], \"\\n\")\n",
    "\n",
    "print(f\"y-train:{y_train.shape}, y-test:{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e13249-0816-4175-b2b6-4277c04530ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten x data (the number arrays) as dense layers' input vectors: (N, 28, 28) -> (N, 28*28)\n",
    "def flatten(x):\n",
    "\n",
    "    N, n, m = x.shape\n",
    "\n",
    "    return x.reshape(N, n*m)\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train = flatten(x_train)\n",
    "x_test = flatten(x_test)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf60ef-6ee7-46e2-83c3-9d26025ecf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the train data into train and validation:\n",
    "\n",
    "N_val = int(0.2*x_train.shape[0])\n",
    "\n",
    "print(f\"N-train = {x_train.shape[0]-N_val}, N-val = {N_val}, N-test = {x_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fb7c82-3045-49c1-a22f-b510d8aeffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:N_val]\n",
    "x_train = x_train[N_val:]\n",
    "\n",
    "y_val = y_train[:N_val]\n",
    "y_train = y_train[N_val:]\n",
    "\n",
    "print(f\"x-train:{x_train.shape}, x-val:{x_val.shape}, x-test:{x_test.shape}\")\n",
    "print(f\"y-train:{y_train.shape}, y-val:{y_val.shape}, y-test:{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297d543-bb47-455f-9cc3-0e129221f760",
   "metadata": {},
   "source": [
    "### __2. Neural network modeling:__\n",
    "<font size=3>\n",
    "    \n",
    "2.1 Define initial layer's shape;\\\n",
    "2.2 Define output layer's shape and its [activation function](https://keras.io/api/layers/activations/);\\\n",
    "2.3 Define hidden layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d179901f-6e79-49de-9d8a-7b52244fb0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "In = keras.Input(shape=(x_train.shape[1],))\n",
    "\n",
    "x = layers.Dense(200, activation=\"relu\")(In)\n",
    "\n",
    "Out = layers.Dense(y_train.shape[1], activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=In, outputs=Out)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626664fc-593b-4539-ac60-4903c5734b58",
   "metadata": {},
   "source": [
    "### __3. Model compilation:__\n",
    "<font size=3>\n",
    "\n",
    "3.1 Define [optimizer](https://keras.io/api/optimizers/);\\\n",
    "3.2 Define [loss function](https://keras.io/api/losses/);\\\n",
    "3.3 Define [validation metric](https://keras.io/api/metrics/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a84098-027b-43c5-ab82-b8120cf530ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beda4521-0d6c-42fe-995f-dd52c4ae9bc1",
   "metadata": {},
   "source": [
    "### __4. Train and validation__\n",
    "<font size=3>\n",
    "    \n",
    "Here, using the training data, the optimizer updates the values of the model's inner parameters (_i.e._, weights, biases, etc.) over the epochs while minimizing/maximizing the loss function. Meanwhile, the model's performance is measured for each epoch using the validation data. At this workflow stage, we model the neural network architecture to avoid [overfitting and underfitting](https://www.geeksforgeeks.org/underfitting-and-overfitting-in-machine-learning/).\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374802ea-faf1-4634-94aa-5916b91ff459",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "report = model.fit(x_train, y_train, validation_data=[x_val, y_val], batch_size=200, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f88d8d3-c3dc-4366-8b00-5293061235f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.history\n",
    "\n",
    "loss = report.history['loss']\n",
    "val_loss = report.history['val_loss']\n",
    "\n",
    "acc = report.history['acc']\n",
    "val_acc = report.history['val_acc']\n",
    "\n",
    "epochs = np.linspace(1, len(loss), len(loss))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "ax[0].plot(epochs, loss, label=\"loss\")\n",
    "ax[0].plot(epochs, val_loss, label=\"cal-loss\")\n",
    "ax[0].set_ylabel(\"Loss function\")\n",
    "\n",
    "ax[1].plot(epochs, acc, label=\"acc\")\n",
    "ax[1].plot(epochs, val_acc, label=\"cal-acc\")\n",
    "ax[1].set_ylabel(\"Metric function\")\n",
    "\n",
    "for i in [0, 1]:\n",
    "    ax[i].set_xlabel(\"epochs\")\n",
    "    ax[i].legend()\n",
    "    ax[i].grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8686e6-36cf-414e-8fed-238a7c2024ad",
   "metadata": {},
   "source": [
    "### __5. Final training__\n",
    "<font size=3>\n",
    "\n",
    "Once the modeling is completed, we concatenate train and validation data to fit again the model.\n",
    "\n",
    "__Note:__ use the same number of __epochs__ and __batch-size__ from the previous step.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e36fb8-7f88-49ad-8443-e244c007c30b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45ed3c5-ea74-419a-b97d-663fbc508a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0e875dc-7d57-42fb-a03b-19948e2de183",
   "metadata": {},
   "source": [
    "### __6. Test evaluation__:\n",
    "\n",
    "    6.1 Make the evaluation using the test data;\n",
    "    6.1 Make some predictions to visualize the results;\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f60cef-a1ab-40c6-b3ec-2db46e398139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a50a3c3-88e9-4e9b-8528-c55cb170dc05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd1006c9-50c7-4341-a265-a9221ae1ebca",
   "metadata": {},
   "source": [
    "### __7. Saving the model__:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f887201-cead-40ec-99cc-7057a328a754",
   "metadata": {},
   "source": [
    "model.save_weights(\"weights/mnist.weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216ee526-ca72-467b-86aa-7fa56c604c7d",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "For model __loading__, see [2.2-notebook](2.2-notebook.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
