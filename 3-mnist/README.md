# __3. The MNIST hand written task__

1. __Theroy:__ Fundamental explanations on derivatives; Maximum and minimum of a function; The gradient operation; The Sochastic Gradient Descent algorithm; The Backpropagation mechanism;
2. __Theroy:__ The Vanishing Gradient problem; ReLU activation function; Normalization layer;
3. __Theroy:__ One-hot encoding; Softmax activation function; Cross-entopy loss function;
4. __Hands on:__ MLP for MNIST classification;
5. __Hands on:__ Experiments on MNIST with MLP model. 